{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DR9gHVuRJfJ"
   },
   "source": [
    "**1. Prerequisites**\n",
    "\n",
    "Enable GPU, if using google colab or AWS SageMaker Studio Lab.\n",
    "\n",
    "**2. Find libraries**\n",
    "\n",
    "By default, Google Colab is not able to run numba + CUDA, because two libraries are not found, libdevice and libnvvm.so . So we need to make sure that these libraries are found in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15682,
     "status": "ok",
     "timestamp": 1648174583092,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "-yFN-w0rux8Z",
    "outputId": "5a5cb42a-fd33-4bd9-bc59-e0cea7025126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘/proc/31/task/31/net’: Invalid argument\n",
      "find: ‘/proc/31/net’: Invalid argument\n",
      "/usr/local/lib/python3.7/dist-packages/jaxlib/cuda/nvvm/libdevice\n",
      "/usr/local/cuda-11.1/nvvm/libdevice\n",
      "/usr/local/cuda-11.0/nvvm/libdevice\n",
      "/usr/local/cuda-10.0/nvvm/libdevice\n",
      "/usr/local/cuda-10.1/nvvm/libdevice\n",
      "find: ‘/proc/31/task/31/net’: Invalid argument\n",
      "find: ‘/proc/31/net’: Invalid argument\n",
      "/usr/local/cuda-11.1/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-11.0/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n"
     ]
    }
   ],
   "source": [
    "!find / -iname 'libdevice'\n",
    "!find / -iname 'libnvvm.so'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_FDbOTRRHjA"
   },
   "source": [
    "**3. Add two libraries to numba**\n",
    "\n",
    "Add the two libraries to numba environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1648174583093,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "7cw9YqXju6Nk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.0/nvvm/libdevice\"\n",
    "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1035,
     "status": "ok",
     "timestamp": 1648174584117,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "ns8ea1KpvGqF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1648174584118,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "ABUJ_UXoxVO8",
    "outputId": "4795522b-47cc-4835-e8cb-aa7e19e5ce8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0            b'Tesla K80'                              [SUPPORTED]\n",
      "                      compute capability: 3.7\n",
      "                           pci device id: 4\n",
      "                              pci bus id: 0\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.detect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R04Sf50qTNaX"
   },
   "source": [
    "**Example for dealing with large input size**\n",
    "\n",
    "From the example, we can compare the time by running multiple gpu threads parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLmDprg2Gj60"
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_atan(x, out):\n",
    "  idx = cuda.grid(1)\n",
    "  out[idx] = math.atan(x[idx])\n",
    "  \n",
    "@cuda.jit\n",
    "def gpu_atan_stride(x, out):\n",
    "  start = cuda.grid(1)\n",
    "  stride = cuda.gridsize(1)\n",
    "  for i in range(start, x.shape[0], stride): \n",
    "    out[i] = math.atan(x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulk4GZuNINC_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(256*1000000,dtype=np.float32)\n",
    "# move input data to the device\n",
    "d_a = cuda.to_device(a)\n",
    "# create output data on the device\n",
    "d_out = cuda.device_array_like(d_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228086,
     "status": "ok",
     "timestamp": 1648099461454,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "tyljLhI5IQZM",
    "outputId": "7ffec9a6-c3ab-41d2-e4f8-3629407d166a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('https://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/usr/local/lib/python3.7/dist-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda-10.0/nvvm/libdevice.\n",
      "\n",
      "For more information about alternatives visit: ('https://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 47s, sys: 381 ms, total: 3min 48s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%time gpu_atan_stride[1, 1](d_a, d_out); cuda.synchronize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1648099461456,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "rXPKkzhoIlhR",
    "outputId": "530b06f1-4d67-415e-f0ef-e5be199fba59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 153 ms, sys: 9.01 ms, total: 162 ms\n",
      "Wall time: 161 ms\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS TWICE. \n",
    "# sometimes, the first time, the timing is way too large for some reason, \n",
    "# and not representative of the actual timing\n",
    "# you should get something around 13 ms. \n",
    "%time gpu_atan[1000000,256](d_a, d_out); cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SGyige4TaWF"
   },
   "source": [
    "**Example : Calculate square of matrix and sum the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3SO8cETLDLi"
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def gpu_sqr(out): \n",
    "  # get the thread coordinates in 2D\n",
    "  i1, i2 = cuda.grid(2)\n",
    "  out[i1][i2] = out[i1][i2]*out[i1][i2]\n",
    "\n",
    "@cuda.jit\n",
    "def gpu_add(a, b, out):\n",
    "  i1, i2 = cuda.grid(2)\n",
    "  out[i1][i2] = a[i1][i2] + b[i1][i2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1648099569465,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "tnOEGiE1MsjX",
    "outputId": "4c44dad6-5878-4e39-923a-47d82c3e0721"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(12).reshape(3,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648099570799,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "tXIynaqjM1_T",
    "outputId": "76301497-3f65-4ec6-b8d2-899327f04dbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   4,   9],\n",
       "       [ 16,  25,  36,  49],\n",
       "       [ 64,  81, 100, 121]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "# we use two blocks, side-by-side in the horizontal direction\n",
    "blocks = (1,2)\n",
    "# each block has 6 threads arranged in 3 lines and 2 columns\n",
    "threads_per_block = (3,2)\n",
    "gpu_sqr[blocks, threads_per_block](d_a)\n",
    "d_a.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648099571728,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "EUyf6lr6NCv0",
    "outputId": "9f45ec42-02c2-417c-e474-efb0eaa6e724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "[[  0  10  20  30]\n",
      " [ 40  50  60  70]\n",
      " [ 80  90 100 110]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(12).reshape(3,4)\n",
    "b = np.arange(0,120,10).reshape(3,4)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1648099573209,
     "user": {
      "displayName": "Aishwarya Raghavan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhOH3mS_8naFTFFWVTnbUxVA3eNRsuCaN8kt_iwjA=s64",
      "userId": "11661708710217793464"
     },
     "user_tz": 300
    },
    "id": "xv9zmesKNcvO",
    "outputId": "e1266367-7f71-4a16-d56b-3ca8f504a9c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   4   9]\n",
      " [ 16  25  36  49]\n",
      " [ 64  81 100 121]]\n",
      "[[    0   100   400   900]\n",
      " [ 1600  2500  3600  4900]\n",
      " [ 6400  8100 10000 12100]]\n",
      "[[    0   101   404   909]\n",
      " [ 1616  2525  3636  4949]\n",
      " [ 6464  8181 10100 12221]]\n"
     ]
    }
   ],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_out = cuda.device_array_like(d_a)\n",
    "# we use two blocks, side-by-side in the horizontal direction\n",
    "blocks = (1,2)\n",
    "# each block has 6 threads arranged in 3 lines and 2 columns\n",
    "threads_per_block = (3,2)\n",
    "gpu_sqr[blocks, threads_per_block](d_a)\n",
    "gpu_sqr[blocks, threads_per_block](d_b)\n",
    "\n",
    "gpu_add[blocks, threads_per_block](d_a, d_b, d_out)\n",
    "\n",
    "print(d_a.copy_to_host())\n",
    "print(d_b.copy_to_host())\n",
    "print(d_out.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7p3KlNyrQveJ"
   },
   "source": [
    "**Reference**\n",
    "\n",
    "1. [Cuda Kernel Python](https://thedatafrog.com/en/articles/cuda-kernel-python/)\n",
    "2. [Numba Cuda Example](https://github.com/cbernet/maldives/blob/master/numba/numba_cuda.ipynb)\n",
    "3. [Cuda Architecture](http://tdesell.cs.und.edu/lectures/cuda_2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82rOTpI2Q6y8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOIHLoRywzmaMfv3sGx3aPw",
   "name": "Cuda_v1.ipynb",
   "provenance": [
    {
     "file_id": "1R5FuE1chwHWWeJurA975J3nGrokmd36p",
     "timestamp": 1648099154313
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
