{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffd0b01",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6aac4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebda395",
   "metadata": {},
   "source": [
    "### 2. Import from mlcblab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f32bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcvlab.models.nn1 import NN1\n",
    "from mlcvlab.models.nn2 import NN2\n",
    "from mlcvlab.nn.losses import l2\n",
    "from mlcvlab.optim.sgd import SGD\n",
    "from mlcvlab.optim.adam import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd0230",
   "metadata": {},
   "source": [
    "### 3. Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f80cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608dc18",
   "metadata": {},
   "source": [
    "### 4.Example code to load data and view image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebaa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(x, index):\n",
    "    some_digit = x[0]\n",
    "    some_digit_image = some_digit.reshape((28, 28))\n",
    "\n",
    "    plt.imshow(some_digit_image, cmap='binary')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23dbe4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8199fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_digit(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deaf6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a956df89",
   "metadata": {},
   "source": [
    "### 5. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7367075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    '''Loads the whole dataset with true labels included.'''\n",
    "    x, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "    return x,y\n",
    "\n",
    "def prepare_data(x, y):\n",
    "    '''Converts 10-ary labels in binary labels. If even then label is 1 otherwise 0.'''\n",
    "    y = y.astype(int)\n",
    "    y = y.reshape(len(y),1)\n",
    "    y =  (y+1) % 2\n",
    "    return x, y\n",
    "\n",
    "def split_train_test(x,y):\n",
    "    '''Partitioning the dataset into 10,000 test samles and the remaining 60,000 as training samples. \n",
    "    The shape  of the data will be M x N where M = 784 and N = 60000 for X and N = 10000 for y.'''   \n",
    "    X_train, X_test = x[:60000].T, x[60000:].T\n",
    "    y_train, y_test = y[:60000].T, y[60000:].T\n",
    "    \n",
    "    # adding -1 to the end of every x  as a bias term\n",
    "    bias_train = np.ones((1, np.shape(X_train)[1])) * -1\n",
    "    bias_test = np.ones((1, np.shape(X_test)[1])) * -1\n",
    "    \n",
    "    X_train = np.append(X_train, bias_train, axis = 0)\n",
    "    X_test = np.append(X_test, bias_test, axis = 0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def initialize_model(X_train, X_test, y_train, y_test):\n",
    "    '''Setting up the size of the weights/layer vectors. W0 is M x K shape where M = arbitrary number and K = 785 and W1 is M x 1 which is 60000 x 1 '''\n",
    "\n",
    "    # multiple ways to initialize the weights\n",
    "    \n",
    "    # Initialization with ones\n",
    "    # W = np.ones((np.shape(X_train)[0],1)) \n",
    "    \n",
    "    # Random Initialization\n",
    "    # W = np.random.rand(np.shape(X_train)[0], 1)\n",
    "    \n",
    "    # Xavier initialization\n",
    "    W = np.random.randn(np.shape(X_train)[0], 1) * np.sqrt(1/np.shape(X_train)[0])\n",
    "    \n",
    "    \n",
    "    # set the last term to -1 as bias term\n",
    "    W[-1] = -1\n",
    "    \n",
    "    one_layer_nn  = NN1()\n",
    "    one_layer_nn.W = W\n",
    "    one_layer_nn.layers[0].W = W\n",
    "\n",
    "    return one_layer_nn\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    '''Training the model using SGD or Adam optimizer.'''\n",
    "    final_W = SGD(model, X_train, y_train, lr=0.1)\n",
    "    # final_W = Adam(model, X_train, y_train)\n",
    "\n",
    "    return final_W\n",
    "\n",
    "def test_model(model, X_test, y_test, final_W):\n",
    "    '''Tests the accuracy of the neural network.'''\n",
    "    accuracy = None\n",
    "    model.W = final_W[0]\n",
    "    \n",
    "    # get the predictions of the algorithm using testing x as the input\n",
    "    y_hat = model.nn1(X_test)\n",
    "\n",
    "    # get the number of test instances\n",
    "    T = np.shape(y_test)[1]\n",
    "\n",
    "    A = np.absolute(y_test - y_hat)\n",
    " \n",
    "    # check if the value is greater than 0 and set it 1 if so.\n",
    "    for x in range(np.shape(A)[1]):\n",
    "            if A[0][x] > 0: \n",
    "                A[0][x] = 1\n",
    "    # calculate the accuracy \n",
    "    accuracy = 1/T * np.sum(A)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49c082",
   "metadata": {},
   "source": [
    "### 6. Run the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6270e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load data\n",
    "x, y = load_dataset()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#prepare data\n",
    "x, y = prepare_data(x,y)\n",
    "\n",
    "# split data set\n",
    "X_train, X_test, y_train, y_test = split_train_test(x,y)\n",
    "\n",
    "#print(\"Shape of train_y before initialization: \",np.shape(y_train))\n",
    "\n",
    "\n",
    "#initialize model\n",
    "model = initialize_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "#training model\n",
    "final_W = train_model(model, X_train, y_train)\n",
    "print(f\"Completed training model - final W : {final_W}\")\n",
    "\n",
    "#testing model\n",
    "accuracy = test_model(model, X_test, y_test, final_W)\n",
    "percentage = 100 * accuracy\n",
    "print(f\"Completed testing model (nn1) - Accuracy : {percentage:2.1f}%\")     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
