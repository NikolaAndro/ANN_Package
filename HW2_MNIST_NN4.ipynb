{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import from mlcblab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcvlab.models.nn4 import NN4\n",
    "from mlcvlab.nn.losses import l2\n",
    "from mlcvlab.optim.sgd import SGD\n",
    "from mlcvlab.optim.async_sgd import async_sgd\n",
    "from mlcvlab.optim.sync_sgd import sync_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    '''Loads the whole dataset with true labels included.'''\n",
    "    x, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "    return x,y\n",
    "\n",
    "def prepare_data(x, y):\n",
    "    '''Converts 10-ary labels in binary labels. If even then label is 1 otherwise 0.'''\n",
    "    y = y.astype(int)\n",
    "    y = y.reshape(len(y),1)\n",
    "    y =  (y+1) % 2\n",
    "    return x, y\n",
    "\n",
    "def split_train_test(x,y):\n",
    "    '''Partitioning the dataset into 10,000 test samles and the remaining 60,000 as training samples. \n",
    "    The shape  of the data will be M x N where M = 784 and N = 60000 for X and N = 10000 for y.'''   \n",
    "    #X_train, X_test = x[:60000].T, x[60000:].T\n",
    "    #y_train, y_test = y[:60000].T, y[60000:].T\n",
    "    X_train, X_test = x[:6000].T, x[69000:].T\n",
    "    y_train, y_test = y[:6000].T, y[69000:].T\n",
    "    \n",
    "    # adding -1 to the end of every x  as a bias term\n",
    "    bias_train = np.ones((1, np.shape(X_train)[1])) * -1\n",
    "    bias_test = np.ones((1, np.shape(X_test)[1])) * -1\n",
    "    \n",
    "    X_train = np.append(X_train, bias_train, axis = 0)\n",
    "    X_test = np.append(X_test, bias_test, axis = 0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def minibatch(x_train,y_train,K):\n",
    "    # Batch Size: K\n",
    "    # X_train_batches, y_train_batches should be a list of lists of size K.\n",
    "    x_train = x_train.T\n",
    "    y_train = y_train.T\n",
    "\n",
    "    x_train_batches = np.array([x_train[i:i+K].T for i in range(0, len(x_train), K)])\n",
    "    y_train_batches = np.array([y_train[i:i+K].T for i in range(0, len(y_train), K)])\n",
    " \n",
    "    return x_train_batches, y_train_batches\n",
    "\n",
    "def initialize_model(M_0,M_1,M_2,M_3, use_batch_norm = True, dropout_p = 0.5):  \n",
    "    #Initialize the weights. Adding -1 for the bias term at the end of the vector.\n",
    "    # Random initialization\n",
    "    #W0 = np.random.rand(np.shape(X_train)[0],M_0) # K x M_1 = 785 x 120\n",
    "    W0 = np.ones((np.shape(X_train)[0],M_0)) # K x M_1 = 785 x 120\n",
    "    W0 = np.random.randn(np.shape(W0)[0], np.shape(W0)[1]) * np.sqrt(2/np.shape(W0)[0])\n",
    "    \n",
    "    # He initialization\n",
    "    W1 = np.ones((M_0,M_1)) # 120 x 100\n",
    "    W1 = np.random.randn(np.shape(W1)[0], np.shape(W1)[1]) * np.sqrt(2/np.shape(W1)[0])\n",
    "\n",
    "    W2 = np.ones((M_1,M_2)) # 100 x 80\n",
    "    W2 = np.random.randn(np.shape(W2)[0], np.shape(W2)[1]) * np.sqrt(2/np.shape(W2)[0])\n",
    "\n",
    "    # Xavier initialization\n",
    "    W3 = np.random.randn(M_2, M_3) * np.sqrt(1/M_2)\n",
    "\n",
    "    print(f\"\\nSize of W0 : {W0.shape}, Size of W1 : {W1.shape}, Size of W2 : {W2.shape}, Size of W3 : {W3.shape}\\n\\n\")\n",
    "    four_layer_nn  = NN4(use_batchnorm=use_batch_norm, dropout_param=dropout_p)\n",
    "    four_layer_nn.layers[0].W = W0\n",
    "    four_layer_nn.layers[1].W = W1\n",
    "    four_layer_nn.layers[2].W = W2\n",
    "    four_layer_nn.layers[3].W = W3\n",
    "\n",
    "    four_layer_nn.dropout_param = dropout_p\n",
    "\n",
    "    return four_layer_nn\n",
    "\n",
    "def train_model(model, x_train_batches, y_train_batches, num_epochs=100, learning_rate=0.1):\n",
    "    #TODO : Call async_SGD and sync_SGD to train two versions of the same model. Compare their outcomes and runtime.\n",
    "    #Update both your models with final updated weights and return them\n",
    "    model_async = async_sgd(model, x_train_batches, y_train_batches,R = num_epochs, lr = learning_rate)\n",
    "    # model_sync = sync_sgd(model, X_train_batches, y_train_batches)\n",
    "    model_sync = None\n",
    "    return model_async, model_sync\n",
    "\n",
    "def test_model(model, X_test, y_test):\n",
    "    '''Tests the accuracy of the neural network.'''\n",
    "    accuracy = None\n",
    "    \n",
    "    # get the number of test instances\n",
    "    T = np.shape(y_test)[1]\n",
    "    \n",
    "    # get the predictions of the algorithm using testing x as the input\n",
    "    \n",
    "    y_hat = np.zeros(np.shape(y_test))\n",
    "    \n",
    "    for index, image in enumerate(X_test.T):\n",
    "        y_hat[0][index] = model.nn4(image,'test')\n",
    "\n",
    "    \n",
    "\n",
    "    A = np.absolute(y_test - y_hat)\n",
    "    \n",
    "    # check if the value is greater than 0 and set it 1 if so.\n",
    "    for x in range(np.shape(A)[1]):\n",
    "            if A[0][x] > 0: \n",
    "                A[0][x] = 1\n",
    "\n",
    "    # calculate the accuracy \n",
    "    accuracy = 1/T * np.sum(A)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "x, y = load_dataset()\n",
    "\n",
    "#prepare data\n",
    "x, y = prepare_data(x,y)\n",
    "\n",
    "# split data set\n",
    "X_train, X_test, y_train, y_test = split_train_test(x,y)\n",
    "\n",
    "#initialize model\n",
    "M_1 = 120\n",
    "M_2 = 100\n",
    "M_3 = 80\n",
    "M_4 = 1 # Layer 4 must be 1 since this is a binary classification problem\n",
    "dropout_p_val = 0.5\n",
    "\n",
    "model = initialize_model(M_1,M_2,M_3,M_4, use_batch_norm = True, dropout_p = dropout_p_val)\n",
    "\n",
    "K = 300\n",
    "x_train_batches, y_train_batches = minibatch(X_train,y_train,K)\n",
    "\n",
    "#set values for training model\n",
    "\n",
    "num_epochs = 1\n",
    "learning_rate = 0.1\n",
    "model_async, model_sync = train_model(model, x_train_batches, y_train_batches, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "print(f\"\\n\\nCompleted training, now testing...\")   \n",
    "\n",
    "#testing model\n",
    "accuracy_async = test_model(model_async, X_test, y_test) * 100\n",
    "print(f\"\\n\\nCompleted testing model using asynchronous SGD - Accuracy : {accuracy_async}%\\n\")   \n",
    "\n",
    "#accuracy_sync = test_model(model_sync, X_test, y_test)\n",
    "#print(f\"Completed testing model using synchronous SGD - Accuracy : {accuracy_sync}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
